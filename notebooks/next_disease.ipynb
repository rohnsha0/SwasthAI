{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Rohan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "data = pd.read_csv(r'D:\\\\Code\\\\Projects\\\\medbuddyAPI\\\\datasets\\\\symptom_checker\\\\disease_sympts_prec_full.csv')\n",
    "data['symptoms'] = data['symptoms'].apply(lambda x: ' '.join([word for word in nltk.word_tokenize(x.lower()) if word not in string.punctuation]))\n",
    "tokenized_texts = data['symptoms'].tolist()\n",
    "symptom_vocab = set()\n",
    "for text in tokenized_texts:\n",
    "    symptom_vocab.update(text.split())\n",
    "symptom_vocab_size = len(symptom_vocab) + 1\n",
    "word_to_index = {word: index for index, word in enumerate(symptom_vocab, start=1)}\n",
    "sequences = [[word_to_index[word] for word in text.split()] for text in tokenized_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for seq in sequences:\n",
    "    for i in range(1, len(seq)):\n",
    "        X.append(seq[:i])\n",
    "        y.append(seq[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = max(len(seq) for seq in X)\n",
    "X = np.array(pad_sequences(X, maxlen=max_seq_len))\n",
    "y = np.array(to_categorical(y, num_classes=symptom_vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(symptom_vocab_size, 64, input_length=max_seq_len))\n",
    "model.add(LSTM(72))\n",
    "model.add(Dense(symptom_vocab_size, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "797/797 [==============================] - 11s 11ms/step - loss: 2.7869 - accuracy: 0.3525 - val_loss: 1.2016 - val_accuracy: 0.7262\n",
      "Epoch 2/100\n",
      "797/797 [==============================] - 9s 11ms/step - loss: 0.8941 - accuracy: 0.7870 - val_loss: 0.4718 - val_accuracy: 0.8899\n",
      "Epoch 3/100\n",
      "797/797 [==============================] - 9s 11ms/step - loss: 0.5695 - accuracy: 0.8420 - val_loss: 0.3297 - val_accuracy: 0.9008\n",
      "Epoch 4/100\n",
      "797/797 [==============================] - 9s 11ms/step - loss: 0.4948 - accuracy: 0.8464 - val_loss: 0.2990 - val_accuracy: 0.9042\n",
      "Epoch 5/100\n",
      "797/797 [==============================] - 9s 11ms/step - loss: 0.4667 - accuracy: 0.8473 - val_loss: 0.2852 - val_accuracy: 0.9006\n",
      "Epoch 6/100\n",
      "797/797 [==============================] - 8s 11ms/step - loss: 0.4507 - accuracy: 0.8493 - val_loss: 0.2736 - val_accuracy: 0.9011\n",
      "Epoch 7/100\n",
      "797/797 [==============================] - 9s 11ms/step - loss: 0.4421 - accuracy: 0.8496 - val_loss: 0.2738 - val_accuracy: 0.9044\n",
      "Epoch 8/100\n",
      "797/797 [==============================] - 9s 11ms/step - loss: 0.4358 - accuracy: 0.8505 - val_loss: 0.2737 - val_accuracy: 0.9009\n",
      "Epoch 9/100\n",
      "797/797 [==============================] - 9s 11ms/step - loss: 0.4307 - accuracy: 0.8509 - val_loss: 0.2631 - val_accuracy: 0.9044\n",
      "Epoch 10/100\n",
      "797/797 [==============================] - 9s 11ms/step - loss: 0.4268 - accuracy: 0.8506 - val_loss: 0.2669 - val_accuracy: 0.9042\n",
      "Epoch 11/100\n",
      "797/797 [==============================] - 9s 11ms/step - loss: 0.4243 - accuracy: 0.8492 - val_loss: 0.2584 - val_accuracy: 0.9009\n",
      "Epoch 12/100\n",
      "797/797 [==============================] - 9s 12ms/step - loss: 0.4234 - accuracy: 0.8509 - val_loss: 0.2599 - val_accuracy: 0.9041\n",
      "Epoch 13/100\n",
      "797/797 [==============================] - 9s 11ms/step - loss: 0.4210 - accuracy: 0.8510 - val_loss: 0.2673 - val_accuracy: 0.9008\n",
      "Epoch 14/100\n",
      "797/797 [==============================] - 9s 11ms/step - loss: 0.4201 - accuracy: 0.8501 - val_loss: 0.2653 - val_accuracy: 0.9044\n",
      "Epoch 15/100\n",
      "797/797 [==============================] - 9s 11ms/step - loss: 0.4167 - accuracy: 0.8520 - val_loss: 0.2657 - val_accuracy: 0.9011\n",
      "Epoch 16/100\n",
      "797/797 [==============================] - 9s 11ms/step - loss: 0.4189 - accuracy: 0.8497 - val_loss: 0.2644 - val_accuracy: 0.9044\n",
      "Epoch 17/100\n",
      "797/797 [==============================] - 9s 11ms/step - loss: 0.4147 - accuracy: 0.8522 - val_loss: 0.2612 - val_accuracy: 0.9009\n",
      "Epoch 18/100\n",
      "797/797 [==============================] - 9s 11ms/step - loss: 0.4154 - accuracy: 0.8521 - val_loss: 0.2678 - val_accuracy: 0.9042\n",
      "Epoch 19/100\n",
      "797/797 [==============================] - 9s 12ms/step - loss: 0.4137 - accuracy: 0.8518 - val_loss: 0.2710 - val_accuracy: 0.9008\n",
      "Epoch 20/100\n",
      "797/797 [==============================] - 9s 11ms/step - loss: 0.4134 - accuracy: 0.8511 - val_loss: 0.2642 - val_accuracy: 0.9042\n",
      "Epoch 21/100\n",
      "797/797 [==============================] - 9s 12ms/step - loss: 0.4132 - accuracy: 0.8505 - val_loss: 0.2634 - val_accuracy: 0.9009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a7208fdff0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 93.15%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, y, verbose=0)\n",
    "print(\"Model Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"nextSymptomData.pickle\", \"wb\") as f:\n",
    "    pickle.dump((word_to_index, max_seq_len), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 410ms/step\n",
      "Given the sequence:  itching, skin_rashs, headache\n",
      "The predicted next symptom is:  nausea\n"
     ]
    }
   ],
   "source": [
    "new_sequence = \"itching, skin_rashs, headache\"\n",
    "new_sequence = new_sequence.lower()\n",
    "tokenized_sequence = [word for word in nltk.word_tokenize(new_sequence) if word not in string.punctuation]\n",
    "sequence_indices = [word_to_index.get(word, 0) for word in tokenized_sequence]\n",
    "padded_sequence = pad_sequences([sequence_indices], maxlen=max_seq_len)\n",
    "\n",
    "prediction = model.predict(padded_sequence)\n",
    "next_symptom_index = np.argmax(prediction[0])\n",
    "next_symptom_word = list(word_to_index.keys())[list(word_to_index.values()).index(next_symptom_index)]\n",
    "\n",
    "print(\"Given the sequence: \", new_sequence)\n",
    "print(\"The predicted next symptom is: \", next_symptom_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Rohan\\AppData\\Local\\Temp\\tmpg1d58gh_\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Rohan\\AppData\\Local\\Temp\\tmpg1d58gh_\\assets\n"
     ]
    }
   ],
   "source": [
    "# Convert the Keras model to a TensorFlow Lite model file\n",
    "converter= tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "\n",
    "# Save the TensorFlow Lite model to a file\n",
    "with open('diseasePredV1.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
