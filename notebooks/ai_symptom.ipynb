{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/5\n",
      "154/154 [==============================] - 21s 101ms/step - loss: 1.9802 - accuracy: 0.6140\n",
      "Epoch 2/5\n",
      "154/154 [==============================] - 21s 134ms/step - loss: 0.0723 - accuracy: 0.9988\n",
      "Epoch 3/5\n",
      "154/154 [==============================] - 18s 119ms/step - loss: 0.0181 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "154/154 [==============================] - 18s 119ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "154/154 [==============================] - 17s 113ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 390ms/step\n",
      "Predicted disease: Diabetes \n",
      "Precautions: have balanced diet, exercise, consult doctor, follow up\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Load the data from the provided database\n",
    "data = pd.read_csv(r'D:\\\\Code\\\\Projects\\\\medbuddyAPI\\\\datasets\\\\symptom_checker\\\\disease_sympts_prec_full.csv')\n",
    "\n",
    "# Preprocess the data\n",
    "symptoms = data['symptoms'].apply(lambda x: ' '.join(x.split(',')))\n",
    "diseases = data['disease']\n",
    "\n",
    "# Tokenize the symptoms\n",
    "all_symptoms = ' '.join(symptoms).split()\n",
    "symptom_counts = Counter(all_symptoms)\n",
    "symptom_vocab = sorted(symptom_counts, key=symptom_counts.get, reverse=True)\n",
    "symptom_to_idx = {symptom: idx for idx, symptom in enumerate(symptom_vocab)}\n",
    "\n",
    "# Convert symptoms to sequences\n",
    "sequences = [[symptom_to_idx[token] for token in word_tokenize(symptom.lower()) if token in symptom_to_idx] for symptom in symptoms]\n",
    "max_length = max([len(seq) for seq in sequences])\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length)\n",
    "\n",
    "# Encode diseases as integers\n",
    "disease_labels = diseases.unique().tolist()\n",
    "disease_encoder = {label: idx for idx, label in enumerate(disease_labels)}\n",
    "encoded_diseases = [disease_encoder[disease] for disease in diseases]\n",
    "\n",
    "# Create text embeddings\n",
    "vocab_size = len(symptom_vocab)\n",
    "embedding_dim = 100\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(len(disease_labels), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(padded_sequences, np.array(encoded_diseases), epochs=5, batch_size=32)\n",
    "\n",
    "# Symptom checker function\n",
    "def symptom_checker(symptoms):\n",
    "    tokenized_symptoms = [symptom_to_idx.get(token, 0) for token in word_tokenize(' '.join(symptoms).lower())]\n",
    "    padded_symptoms = pad_sequences([tokenized_symptoms], maxlen=max_length)\n",
    "    predictions = model.predict(padded_symptoms)\n",
    "    predicted_index = np.argmax(predictions[0])\n",
    "    predicted_disease = disease_labels[predicted_index]\n",
    "    precautions = data[data['disease'] == predicted_disease]['precautions'].iloc[0]\n",
    "    print(f\"Predicted disease: {predicted_disease}\")\n",
    "    print(f\"Precautions: {precautions}\")\n",
    "\n",
    "# Example usage\n",
    "symptom_checker(['fatigue','weight_loss','restlessness','lethargy','irregular_sugar_level','blurred_and_distorted_vision','obesity','increased_appetite','polyuria'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Rohan\\AppData\\Local\\Temp\\tmpyy_682so\\assets\n"
     ]
    }
   ],
   "source": [
    "# Convert the Keras model to a TensorFlow Lite model file\n",
    "converter= tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "\n",
    "# Save the TensorFlow Lite model to a file\n",
    "with open('symptom_checker_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('symptom_varsV1.pickle', 'wb') as f:\n",
    "    pickle.dump((disease_labels, symptom_to_idx, max_length), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"symptom_checker_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Function to predict disease based on symptoms\n",
    "def predict_disease(symptom_sentence):\n",
    "  symptoms = word_tokenize(symptom_sentence.lower())\n",
    "  tokenized_symptoms = tokenizer.texts_to_sequences([' '.join(symptoms)])\n",
    "  padded_symptoms = pad_sequences(tokenized_symptoms, maxlen=max_length)\n",
    "\n",
    "  interpreter.resize_tensor_input(input_details[0]['index'], [1, max_length])\n",
    "  interpreter.allocate_tensors()\n",
    "  input_data = np.array([padded_symptoms], dtype=np.float32)\n",
    "  input_data = np.squeeze(input_data, axis=1)\n",
    "  interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "  interpreter.invoke()\n",
    "  \n",
    "  output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "  predicted_index = np.argmax(output_data[0])\n",
    "  predicted_disease = disease_labels[predicted_index]\n",
    "\n",
    "  precautions = data[data['disease'] == predicted_disease]['precautions'].iloc[0]\n",
    "  \n",
    "  return predicted_disease, precautions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m symptom_sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI have fatigue, weight loss, restlessness, lethargy, irregular sugar level, blurred and distorted vision, obesity, increased appetite, and polyuria.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m predicted_disease, precautions \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_disease\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymptom_sentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted disease: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_disease\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecautions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecautions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[14], line 11\u001b[0m, in \u001b[0;36mpredict_disease\u001b[1;34m(symptom_sentence)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_disease\u001b[39m(symptom_sentence):\n\u001b[0;32m     10\u001b[0m   symptoms \u001b[38;5;241m=\u001b[39m word_tokenize(symptom_sentence\u001b[38;5;241m.\u001b[39mlower())\n\u001b[1;32m---> 11\u001b[0m   tokenized_symptoms \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mtexts_to_sequences([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(symptoms)])\n\u001b[0;32m     12\u001b[0m   padded_symptoms \u001b[38;5;241m=\u001b[39m pad_sequences(tokenized_symptoms, maxlen\u001b[38;5;241m=\u001b[39mmax_length)\n\u001b[0;32m     14\u001b[0m   interpreter\u001b[38;5;241m.\u001b[39mresize_tensor_input(input_details[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m], [\u001b[38;5;241m1\u001b[39m, max_length])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "symptom_sentence = \"I have fatigue, weight loss, restlessness, lethargy, irregular sugar level, blurred and distorted vision, obesity, increased appetite, and polyuria.\"\n",
    "predicted_disease, precautions = predict_disease(symptom_sentence)\n",
    "print(f\"Predicted disease: {predicted_disease}\")\n",
    "print(f\"Precautions: {precautions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted disease: Varicose veins\n",
      "Precautions: lie down flat and raise the leg high, use oinments, use vein compression, dont stand still for long\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the TensorFlow Lite model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"symptom_checker_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Prepare input data\n",
    "symptom_sentence = \"I have fatigue, weight loss, restlessness, lethargy, irregular sugar level, blurred and distorted vision, obesity, increased appetite, and polyuria.\"\n",
    "symptoms = word_tokenize(symptom_sentence.lower())\n",
    "tokenized_symptoms = [symptom_to_idx.get(token, 0) for token in word_tokenize(' '.join(symptoms).lower())]\n",
    "padded_symptoms = pad_sequences([tokenized_symptoms], maxlen=max_length)\n",
    "input_tensor = np.array(padded_symptoms, dtype=np.float32)\n",
    "\n",
    "\n",
    "# Set the input tensor\n",
    "interpreter.set_tensor(input_details[0]['index'], input_tensor)\n",
    "\n",
    "# Run the inference\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get the output tensor\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "predicted_index = np.argmax(output_data[0])\n",
    "predicted_disease = disease_labels[predicted_index]\n",
    "\n",
    "# Print the predicted disease\n",
    "print(f\"Predicted disease: {predicted_disease}\")\n",
    "precautions = data[data['disease'] == predicted_disease]['precautions'].iloc[0]\n",
    "print(f\"Precautions: {precautions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
